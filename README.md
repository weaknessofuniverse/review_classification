## ğŸ§  Review Sentiment Classification

### ğŸ“˜ Project Description

This project focuses on **sentiment classification of product reviews** using both **traditional machine learning** and **transformer-based models**.
We compare the performance of a **TFâ€“IDF + Logistic Regression** baseline against a **fine-tuned Transformer** model on a large dataset of labeled reviews (positive / neutral / negative).

The final transformer model achieved **84% accuracy** and strong macro F1 performance, significantly outperforming the baseline.

---

### ğŸš€ Key Features

* End-to-end sentiment analysis pipeline
* Preprocessing, feature extraction, and evaluation modules
* Baseline (TFâ€“IDF + Logistic Regression) and Transformer comparison
* Modular architecture for reproducibility and extension
* Experiment tracking and model saving

---

### ğŸ“‚ Project Structure

```
REVIEW_CLASSIFICATION/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Original raw data
â”‚   â””â”€â”€ processed/               # Cleaned & preprocessed CSV files
â”‚       â”œâ”€â”€ train.csv
â”‚       â””â”€â”€ test.csv
â”‚
â”œâ”€â”€ experiments/                 # Experiment results & logs
â”‚
â”œâ”€â”€ models/                      # Saved models and training history
â”‚   â”œâ”€â”€ baseline.joblib
â”‚   â”œâ”€â”€ best_model_epoch3_f10.8012
â”‚   â””â”€â”€ training_history.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ sentiment-pipeline.ipynb # Jupyter notebook with full pipeline
â”‚
â”œâ”€â”€ src/                         # Core source code
â”‚   â”œâ”€â”€ baseline.py              # TFâ€“IDF + Logistic Regression
â”‚   â”œâ”€â”€ data_prep.py             # Data loading and preprocessing
â”‚   â”œâ”€â”€ eval.py                  # Evaluation and reporting
â”‚   â”œâ”€â”€ features.py              # Feature extraction
â”‚   â”œâ”€â”€ transformer.py           # Transformer fine-tuning
â”‚   â””â”€â”€ utils.py                 # Helper functions
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # This file
```

---

### âš™ï¸ Architecture Overview

```text
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        Raw Reviews          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Data Preprocessing    â”‚  â†’  Cleaning, tokenization, labeling
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Feature Engineering    â”‚  â†’  TFâ€“IDF or Transformer embeddings
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
        â”‚LogRegâ”‚Transformer â”‚Otherâ”‚
        â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        Evaluation       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Metrics & Comparison  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ“Š Model Performance

#### ğŸ”¹ **Transformer Fine-tuned Model**

| Metric            |   Value   |
| :---------------- | :-------: |
| Accuracy          | **0.840** |
| F1 (macro)        | **0.801** |
| Precision (macro) |   0.804   |
| Recall (macro)    |   0.799   |

**Classification Report (Validation):**

```
              precision    recall  f1-score   support
negative       0.89        0.90       0.89     20000
neutral        0.64        0.59       0.61     10000
positive       0.89        0.91       0.90     20000
accuracy                               0.84     50000
```

âœ… Saved best model to: `models/best_model_epoch3_f10.8012`

---

#### ğŸ”¸ **Baseline: TFâ€“IDF + Logistic Regression**

| Metric     |   Value   |
| :--------- | :-------: |
| Accuracy   | **0.800** |
| F1 (macro) | **0.770** |

**Classification Report:**

```
              precision    recall  f1-score   support
negative       0.87        0.85       0.86     26000
neutral        0.55        0.61       0.58     13000
positive       0.88        0.85       0.86     26000
```

---

### ğŸ’¾ Installation

```bash
git clone https://github.com/weaknessofuniverse/review-classification.git
cd review-classification
pip install -r requirements.txt
```

---

### ğŸ§© Usage

Run preprocessing:

```bash
python src/data_prep.py
```

Train baseline model:

```bash
python src/baseline.py
```

Fine-tune transformer:

```bash
python src/transformer.py
```

Evaluate results:

```bash
python src/eval.py
```

---

### ğŸ“ˆ Future Work

* Expand dataset with multilingual reviews
* Experiment with LLaMA or Mistral-based encoders
* Integrate real-time inference API

